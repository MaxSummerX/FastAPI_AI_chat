"""
–ú–æ–¥—É–ª—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å HeadHunter.ru
"""

import asyncio
import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any, cast
from uuid import UUID

import aiofiles
import httpx
from fastapi import HTTPException
from loguru import logger
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.enum.experience import Experience
from app.models.vacancies import Vacancy
from app.tools.headhunter.headhunter_client import (
    HH_CONCURRENT_REQUESTS,
    HH_MAX_PAGES,
    HH_REQUEST_DELAY,
    HHApiEndpoint,
    get_hh_client,
)


BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
TEMP_DIR = BASE_DIR / "temp_files"

# –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
TEMP_DIR.mkdir(parents=True, exist_ok=True)


def get_user_vacancy_files(user_id: UUID) -> tuple[Path, Path]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É: DEFAULT_VACANCIES_FILE –∏ DEFAULT_FILTERED_VACANCIES_FILE
    –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ, –∏–Ω–∞—á–µ –≤—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    –±—É–¥—É—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ñ–∞–π–ª.

    Args:
        user_id: UUID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        tuple[Path, Path]: (–ø—É—Ç—å –∫ —Å—ã—Ä—ã–º –≤–∞–∫–∞–Ω—Å–∏—è–º, –ø—É—Ç—å –∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º)
    """
    user_temp_dir = TEMP_DIR / str(user_id)
    user_temp_dir.mkdir(parents=True, exist_ok=True)

    return (
        user_temp_dir / "vacancies.json",
        user_temp_dir / "filtered_vacancies.json",
    )


async def fetch_full_vacancy(
    vacancy_id: str,
    hh_client: httpx.AsyncClient,
) -> dict[str, Any]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ ID.

    Args:
        vacancy_id: ID –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–∞ hh.ru
        hh_client: HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API

    Returns:
        dict —Å –ø–æ–ª–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏

    Raises:
        HTTPException: –µ—Å–ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞
    """

    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL
        url = HHApiEndpoint.VACANCIES_BY_ID.format(vacancy_id=vacancy_id)

        response = await hh_client.get(url)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
        response.raise_for_status()

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç
        return cast(dict[str, Any], response.json())

    except httpx.HTTPStatusError as e:
        logger.error(f"HTTP –æ—à–∏–±–∫–∞: {e.response.status_code}")
        raise HTTPException(status_code=e.response.status_code, detail="–í–∞–∫–∞–Ω—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞") from None

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_id}: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ–ø–∏—Å–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}") from None


async def vacancy_create(hh_id: str, query: str, user_id: UUID, hh_client: httpx.AsyncClient) -> Vacancy:
    """
    –°–æ–∑–¥–∞—ë—Ç –æ–±—ä–µ–∫—Ç Vacancy –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö —Å hh.ru.

    Args:
        hh_id: ID –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–∞ hh.ru
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        hh_client: HTTP –∫–ª–∏–µ–Ω—Ç

    Returns:
        Vacancy: –û–±—ä–µ–∫—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
    """

    details = await fetch_full_vacancy(hh_id, hh_client)

    salary = details.get("salary") or {}
    experience = details.get("experience") or {}
    area = details.get("area") or {}
    schedule = details.get("schedule") or {}
    employment = details.get("employment") or {}
    employer = details.get("employer") or {}

    # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏–∑ ISO —Ñ–æ—Ä–º–∞—Ç–∞
    published_at_str = details.get("published_at")
    published_at = None
    if published_at_str:
        try:
            # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO 8601 (–Ω–∞–ø—Ä–∏–º–µ—Ä: "2026-01-07T11:56:31+0300")
            published_at = datetime.fromisoformat(published_at_str)
        except (ValueError, TypeError) as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É {published_at_str}: {e}")

    return Vacancy(
        user_id=user_id,
        hh_id=hh_id,
        query_request=query,
        title=details.get("name"),
        description=details.get("description"),
        salary_from=salary.get("from"),
        salary_to=salary.get("to"),
        salary_currency=salary.get("currency"),
        salary_gross=salary.get("gross"),
        experience_id=experience.get("id"),
        area_id=area.get("id"),
        area_name=area.get("name"),
        schedule_id=schedule.get("id"),
        employment_id=employment.get("id"),
        employer_id=employer.get("id"),
        employer_name=employer.get("name"),
        hh_url=details.get("alternate_url"),
        apply_url=details.get("apply_alternate_url"),
        is_archived=details.get("archived", False),
        raw_data=details,
        published_at=published_at,
    )


async def vacancies_create(
    query: str,
    user_id: UUID,
    hh_client: httpx.AsyncClient,
    session: AsyncSession,
    input_path: str | Path | None = None,
) -> dict[str, int]:
    """
    –ü–∞–∫–µ—Ç–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –ë–î –∏–∑ —Ñ–∞–π–ª–∞.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        hh_client: HTTP –∫–ª–∏–µ–Ω—Ç
        session: SQLAlchemy –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è
        input_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏)

    Returns:
        dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π:
            - total_found: –≤—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ñ–∞–π–ª–µ
            - already_exists: —É–∂–µ –±—ã–ª–æ –≤ –ë–î
            - new_added: –Ω–æ–≤—ã—Ö –¥–æ–±–∞–≤–ª–µ–Ω–æ
            - errors: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫
    """

    if input_path is None:
        _, input_path = get_user_vacancy_files(user_id)

    async with aiofiles.open(input_path, encoding="utf-8") as file:
        content = await file.read()
        vacancies = json.loads(content)

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ ID –≤–∞–∫–∞–Ω—Å–∏–π
    all_ids = [vac.get("id") for vac in vacancies if vac.get("id")]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ —É–∂–µ –µ—Å—Ç—å –≤ –ë–î
    stmt = select(Vacancy.hh_id).where(Vacancy.hh_id.in_(all_ids))
    result = await session.execute(stmt)
    existing_ids = {row.hh_id for row in result}

    new_ids = set(all_ids) - existing_ids

    logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(all_ids)}")
    logger.info(f"–£–∂–µ –≤ –ë–î: {len(existing_ids)}")
    logger.info(f"–ù–æ–≤—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {len(new_ids)}")

    vacancies_to_add = []
    error_count = 0

    for hh_id in new_ids:
        try:
            vacancy = await vacancy_create(hh_id, query, user_id, hh_client)
            vacancies_to_add.append(vacancy)
            await asyncio.sleep(HH_REQUEST_DELAY)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏ {hh_id}: {e}")
            error_count += 1
            continue

    session.add_all(vacancies_to_add)
    await session.commit()
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –ë–î –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    return {
        "total_found": len(all_ids),
        "already_exists": len(existing_ids),
        "new_added": len(vacancies_to_add),
        "errors": error_count,
    }


async def fetch_with_semaphore(
    semaphore: asyncio.Semaphore, client: httpx.AsyncClient, params: dict[str, Any]
) -> dict[str, Any] | None:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π.

    Args:
        semaphore: –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è concurrent requests
        client: HTTP –∫–ª–∏–µ–Ω—Ç
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞

    Returns:
        dict —Å –æ—Ç–≤–µ—Ç–æ–º API –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    async with semaphore:
        try:
            url = HHApiEndpoint.VACANCIES
            response = await client.get(url, params=params)
            if response.status_code != 200:
                logger.warning(f"–ó–∞–ø—Ä–æ—Å —É–ø–∞–ª —Å –æ—à–∏–±–∫–æ–π: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                return None
            logger.info(f"–£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {params.get('page', 'N/A')}")
            return cast(dict[str, Any], response.json())
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ {params}: {e}")
            return None


async def fetch_data_gather(
    params: list[dict[str, Any]],
    max_connections: int,
    hh_client: httpx.AsyncClient,
) -> list[dict[str, Any] | None]:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –≤ –ø—É–ª –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.

    Args:
        params: –°–ø–∏—Å–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
        max_connections: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        hh_client: HTTP –∫–ª–∏–µ–Ω—Ç

    Returns:
        list —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    semaphore = asyncio.Semaphore(max_connections)
    tasks = [fetch_with_semaphore(semaphore, hh_client, param) for param in params]
    return await asyncio.gather(*tasks)


async def fetch_all_hh_vacancies(
    query: str,
    hh_client: httpx.AsyncClient,
    user_id: UUID,
    output_path: str | Path | None = None,
) -> dict[str, Any]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —Ñ–∞–π–ª.
    –∑–∞–ø—Ä–æ—Å -> django OR fastapi OR aiohttp OR litestar OR flask

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä: "django OR fastapi")
        hh_client: HTTP –∫–ª–∏–µ–Ω—Ç
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—É—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏)

    Returns:
        dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π:
            - vacancies_count: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
            - pages_processed: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü

    Raises:
        HTTPException: –ø—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏
    """
    if output_path is None:
        output_path, _ = get_user_vacancy_files(user_id)

    logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å —Å query: '{query}'")
    try:
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ –∑–∞–ø—Ä–æ—Å—É
        url = HHApiEndpoint.VACANCIES
        pages_response = await hh_client.get(
            url,
            params={"text": query, "per_page": 100},
        )
        logger.info(f"‚úÖ HTTP –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω: —Å—Ç–∞—Ç—É—Å {pages_response.status_code}")
        result = pages_response.json()
        pages = int(result["pages"])

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
        if pages >= HH_MAX_PAGES:
            pages = HH_MAX_PAGES
            logger.info(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ {HH_MAX_PAGES} —Å—Ç—Ä–∞–Ω–∏—Ü")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        query_params = [{"text": query, "per_page": 100, "page": i} for i in range(pages)]

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã concurrently
        results = await fetch_data_gather(query_params, HH_CONCURRENT_REQUESTS, hh_client)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞—è None
        vacancies_data = []
        for res in results:
            if res and "items" in res:
                vacancies_data.extend(res["items"])

        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        output_path_obj = Path(output_path)
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        async with aiofiles.open(output_path, "w", encoding="utf-8") as file:
            await file.write(json.dumps(vacancies_data, indent=2, ensure_ascii=False))

        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(vacancies_data)} –≤–∞–∫–∞–Ω—Å–∏–π –≤ {output_path}")

        return {
            "vacancies_count": len(vacancies_data),
            "pages_processed": pages,
        }

    except httpx.HTTPStatusError as e:
        logger.error(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {e.response.status_code}")
        raise HTTPException(
            status_code=e.response.status_code, detail=f"–û—à–∏–±–∫–∞ API hh.ru: {e.response.status_code}"
        ) from None

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∞–∫–∞–Ω—Å–∏–π: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∞–∫–∞–Ω—Å–∏–π: {e}") from None


async def filtered_vacancies(
    user_id: UUID,
    tiers: list[Experience] | None = None,
    input_path: str | Path | None = None,
    output_path: str | Path | None = None,
) -> dict[str, int]:
    """
    –ß–∏—Ç–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ —É—Ä–æ–≤–Ω—é –æ–ø—ã—Ç–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        tiers: –°–ø–∏—Å–æ–∫ —É—Ä–æ–≤–Ω–µ–π –æ–ø—ã—Ç–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (None = –≤—Å–µ —É—Ä–æ–≤–Ω–∏)
        input_path: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏)
        output_path: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏)

    Returns:
        dict —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
    """
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –ø—É—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if input_path is None or output_path is None:
        default_input, default_output = get_user_vacancy_files(user_id)
        input_path = input_path or default_input
        output_path = output_path or default_output

    try:
        # –ï—Å–ª–∏ tiers –Ω–µ —É–∫–∞–∑–∞–Ω –∏–ª–∏ –ø—É—Å—Ç–æ–π, –≤—ã–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –æ–ø—ã—Ç–∞
        if not tiers:
            tiers = list(Experience)
            logger.info(f"Tier –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ —É—Ä–æ–≤–Ω–∏ –æ–ø—ã—Ç–∞: {tiers}")
        else:
            logger.info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—è–º –æ–ø—ã—Ç–∞: {tiers}")

        # –ß—Ç–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        async with aiofiles.open(input_path, encoding="utf-8") as file:
            content = await file.read()
            vacancies = json.loads(content)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∞–∫–∞–Ω—Å–∏–π
        result = []

        for vacancy in vacancies:
            experience = vacancy.get("experience")
            if experience and experience.get("id") in tiers:
                result.append(vacancy)

        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(result)} –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ {len(vacancies)}")

        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        output_path_obj = Path(output_path)
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)

        # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—É—Ç—å –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ–π –∑–∞–ø–∏—Å–∏
        temp_output_path = output_path_obj.with_suffix(f"{output_path_obj.suffix}.tmp")

        # –ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        async with aiofiles.open(temp_output_path, mode="w", encoding="utf-8") as file:
            await file.write(json.dumps(result, indent=2, ensure_ascii=False))

        # –ê—Ç–æ–º–∞—Ä–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–∑–≤–∞–Ω–∏–µ
        shutil.move(temp_output_path, output_path)

        logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_path}")

        return {"filtered": len(result)}

    except FileNotFoundError:
        logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        raise HTTPException(
            status_code=404, detail="–§–∞–π–ª —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É —Å hh.ru."
        ) from None

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π: {e}") from None


async def import_vacancies(
    query: str,
    user_id: UUID,
    session: AsyncSession,
    tiers: list[Experience] | None = None,
) -> dict[str, int]:
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∏–º–ø–æ—Ä—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å hh.ru –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

    –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:
    1. –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å hh.ru ‚Üí —Ñ–∞–π–ª
    2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—é –æ–ø—ã—Ç–∞ ‚Üí –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
    3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –≤ –ë–î

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        session: SQLAlchemy –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è
        tiers: –°–ø–∏—Å–æ–∫ —É—Ä–æ–≤–Ω–µ–π –æ–ø—ã—Ç–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

    Returns:
        dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
            - fetched: —Å–∫–æ–ª—å–∫–æ –ø–æ–ª—É—á–µ–Ω–æ —Å hh.ru
            - filtered: —Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            - total_found: –≤—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ñ–∞–π–ª–µ
            - already_exists: —É–∂–µ –±—ã–ª–æ –≤ –ë–î
            - new_added: –Ω–æ–≤—ã—Ö –¥–æ–±–∞–≤–ª–µ–Ω–æ
            - errors: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫
    """
    logger.info(f"[Background] –ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–π: query='{query}', user_id={user_id}")

    # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç
    hh_client = await get_hh_client()

    try:
        fetch_result = await fetch_all_hh_vacancies(query, hh_client, user_id)
        logger.info("[Background] –®–∞–≥ 1 –∑–∞–≤–µ—Ä—à—ë–Ω: –≤–∞–∫–∞–Ω—Å–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —Å hh.ru")

        # –®–∞–≥ 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        filter_result = await filtered_vacancies(user_id, tiers)
        logger.info("[Background] –®–∞–≥ 2 –∑–∞–≤–µ—Ä—à—ë–Ω: –≤–∞–∫–∞–Ω—Å–∏–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã")

        # –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
        db_result = await vacancies_create(query, user_id, hh_client, session)
        logger.info("[Background] –®–∞–≥ 3 –∑–∞–≤–µ—Ä—à—ë–Ω: –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")

        logger.success(f"[Background] ‚úÖ –ò–º–ø–æ—Ä—Ç –≤–∞–∫–∞–Ω—Å–∏–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω: query='{query}'")

        return {
            "fetched": fetch_result.get("vacancies_count", 0),
            "filtered": filter_result.get("filtered", 0),
            **db_result,
        }

    except HTTPException as e:
        logger.error(f"[Background] HTTP {e.status_code}: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"[Background] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –≤–∞–∫–∞–Ω—Å–∏–π: {e}", exc_info=True)
        raise
