import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Any, cast
from uuid import UUID

import aiofiles
import httpx
from fastapi import HTTPException
from loguru import logger
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.enum.experience import Experience
from app.models.vacancies import Vacancy


BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
TEMP_DIR = BASE_DIR / "temp_files"

HH_API_URL = "https://api.hh.ru/vacancies"
HH_MAX_PAGES = 20  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
HH_REQUEST_DELAY = 0.4  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (rate limiting)
HH_CONCURRENT_REQUESTS = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

DEFAULT_VACANCIES_FILE = TEMP_DIR / "vacancies.json"
DEFAULT_FILTERED_VACANCIES_FILE = TEMP_DIR / "filtered_vacancies.json"


async def fetch_full_vacancy(vacancy_id: str, url: str = HH_API_URL) -> dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏"""
    async with httpx.AsyncClient() as client:
        try:
            # –°–æ–∑–¥–∞—ë–º –∑–∞–ø—Ä–æ—Å –∫ api hh.ru
            response = await client.get(f"{url}/{vacancy_id}", headers={"User-Agent": "parser_vacancies/0.1"})
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
            response.raise_for_status()

            # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
            full_vacancy = response.json()

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç
            return cast(dict[str, Any], full_vacancy)

        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP –æ—à–∏–±–∫–∞: {e.response.status_code}")
            raise HTTPException(status_code=e.response.status_code, detail="–í–∞–∫–∞–Ω—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞") from None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ–ø–∏—Å–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ–ø–∏—Å–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}") from None


async def vacancies_create(
    query: str,
    user_id: UUID,
    session: AsyncSession,
    input_path: str | Path = DEFAULT_FILTERED_VACANCIES_FILE,
) -> None:
    """
    –ü–∞–∫–µ—Ç–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –±–¥
    """
    async with aiofiles.open(input_path, encoding="utf-8") as file:
        content = await file.read()
        vacancies = json.loads(content)

    all_ids = []

    for vac in vacancies:
        id_vac = vac.get("id")
        if id_vac:
            all_ids.append(vac["id"])

    stmt = select(Vacancy.hh_id).where(Vacancy.hh_id.in_(all_ids))
    result = await session.execute(stmt)
    existing_ids = {row.hh_id for row in result}

    new_ids = set(all_ids) - existing_ids

    logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(all_ids)}")
    logger.info(f"–£–∂–µ –≤ –ë–î: {len(existing_ids)}")
    logger.info(f"–ù–æ–≤—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {len(new_ids)}")

    for hh_id in new_ids:
        try:
            details = await fetch_full_vacancy(hh_id)

            if not details:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏ {hh_id}")
                continue

            salary = details.get("salary") or {}
            experience = details.get("experience") or {}
            area = details.get("area") or {}
            schedule = details.get("schedule") or {}
            employment = details.get("employment") or {}
            employer = details.get("employer") or {}

            # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏–∑ ISO —Ñ–æ—Ä–º–∞—Ç–∞
            published_at_str = details.get("published_at")
            published_at = None
            if published_at_str:
                try:
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO 8601 (–Ω–∞–ø—Ä–∏–º–µ—Ä: "2026-01-07T11:56:31+0300")
                    published_at = datetime.fromisoformat(published_at_str)
                except (ValueError, TypeError) as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É {published_at_str}: {e}")

            vacancy = Vacancy(
                user_id=user_id,
                hh_id=hh_id,
                query_request=query,
                title=details.get("name"),
                description=details.get("description"),
                salary_from=salary.get("from"),
                salary_to=salary.get("to"),
                salary_currency=salary.get("currency"),
                salary_gross=salary.get("gross"),
                experience_id=experience.get("id"),
                area_id=area.get("id"),
                area_name=area.get("name"),
                schedule_id=schedule.get("id"),
                employment_id=employment.get("id"),
                employer_id=employer.get("id"),
                employer_name=employer.get("name"),
                hh_url=details.get("alternate_url"),
                apply_url=details.get("apply_alternate_url"),
                is_archived=details.get("archived", False),
                raw_data=details,
                published_at=published_at,
            )

            session.add(vacancy)
            await asyncio.sleep(HH_REQUEST_DELAY)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏ {hh_id}: {e}")
            continue

    await session.commit()
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –±–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


async def fetch_with_semaphore(
    semaphore: asyncio.Semaphore, client: httpx.AsyncClient, url: str, param: dict[str, Any]
) -> dict[str, Any] | None:
    """–í—ã–¥–µ–ª—è–µ–º –∫–∞–Ω–∞–ª –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
    async with semaphore:
        try:
            response = await client.get(url, params=param)
            if response.status_code != 200:
                logger.warning(f"–ó–∞–ø—Ä–æ—Å —É–ø–∞–ª —Å –æ—à–∏–±–∫–æ–π: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                return None
            logger.info(f"–£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {param.get('page', 'N/A')}")
            return cast(dict[str, Any], response.json())
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ {param}: {e}")
            return None


async def fetch_data_gather(param: list, connect: int) -> list[Any]:
    """–û–±—ä–µ–¥–∏–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã –≤ –ø—É–ª"""
    semaphore = asyncio.Semaphore(connect)
    async with httpx.AsyncClient() as client:
        tasks = [fetch_with_semaphore(semaphore, client, url=url, param=data) for data, url in param]
        result = await asyncio.gather(*tasks)
        return cast(list[Any], result)


async def fetch_all_hh_vacancies(
    query: str, url: str = HH_API_URL, input_path: str | Path = DEFAULT_VACANCIES_FILE
) -> dict[str, Any]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    –∑–∞–ø—Ä–æ—Å -> django OR fastapi OR aiohttp OR litestar OR flask
    """
    logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å —Å query: '{query}'")
    try:
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∫–æ–ª-–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ –∑–∞–ø—Ä–æ—Å—É
        async with httpx.AsyncClient() as client:
            pages_response = await client.get(url, params={"text": query, "per_page": 100})
            result = pages_response.json()
            pages = int(result["pages"])
            logger.info(f"–ü–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {pages}")
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
        if pages >= HH_MAX_PAGES:
            pages = HH_MAX_PAGES

        vacancies_data = []

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        query_params = [({"text": query, "per_page": 100, "page": i}, url) for i in range(pages)]

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã concurrently
        results = await fetch_data_gather(query_params, HH_CONCURRENT_REQUESTS)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞—è None
        for res in results:
            if res and "items" in res:
                vacancies_data.extend(res["items"])

        logger.info(f"–í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies_data)}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏ UTF-8
        async with aiofiles.open(input_path, "w", encoding="utf-8") as file:
            await file.write(json.dumps(vacancies_data, indent=2, ensure_ascii=False))

        logger.info(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {input_path}")

        return {"vacancies_count": len(vacancies_data), "pages_processed": pages}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∞–∫–∞–Ω—Å–∏–π: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∞–∫–∞–Ω—Å–∏–π: {e}") from None


async def filtered_vacancies(
    tiers: list[Experience] | None,
    input_path: str | Path = DEFAULT_VACANCIES_FILE,
    output_path: str | Path = DEFAULT_FILTERED_VACANCIES_FILE,
) -> dict[str, int]:
    """
    –ß–∏—Ç–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ tiers –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    """

    try:
        # –ï—Å–ª–∏ tiers –Ω–µ —É–∫–∞–∑–∞–Ω –∏–ª–∏ –ø—É—Å—Ç–æ–π, –≤—ã–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –æ–ø—ã—Ç–∞
        if not tiers:
            tiers = list(Experience)
            logger.info(f"Tier –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ —É—Ä–æ–≤–Ω–∏ –æ–ø—ã—Ç–∞: {tiers}")
        else:
            logger.info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—è–º –æ–ø—ã—Ç–∞: {tiers}")

        # –ß—Ç–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        async with aiofiles.open(input_path, encoding="utf-8") as file:
            content = await file.read()
            vacancies = json.loads(content)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∞–∫–∞–Ω—Å–∏–π
        result = []

        for vacancy in vacancies:
            experience = vacancy.get("experience")
            if experience and experience.get("id") in tiers:
                result.append(vacancy)

        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(result)} –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ {len(vacancies)}")

        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)

        # –ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        async with aiofiles.open(output_path, mode="w", encoding="utf-8") as file:
            await file.write(json.dumps(result, indent=2, ensure_ascii=False))

        logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_path}")

        return {"–ù–∞–π–¥–µ–Ω–æ": len(result)}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∞–∫–∞–Ω—Å–∏–π: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∞–∫–∞–Ω—Å–∏–π: {e}") from None


async def import_vacancies(
    query: str,
    tiers: list[Experience] | None,
    user_id: UUID,
    session: AsyncSession,
) -> None:
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∏–º–ø–æ—Ä—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å hh.ru –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∫ background task, –ø–æ—ç—Ç–æ–º—É –Ω–∏—á–µ–≥–æ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç.
    –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ.
    """
    logger.info(f"[Background] –ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–π: query='{query}', user_id={user_id}")
    try:
        await fetch_all_hh_vacancies(query)
        logger.info("[Background] –®–∞–≥ 1 –∑–∞–≤–µ—Ä—à—ë–Ω: –≤–∞–∫–∞–Ω—Å–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —Å hh.ru")
        await filtered_vacancies(tiers)
        logger.info("[Background] –®–∞–≥ 2 –∑–∞–≤–µ—Ä—à—ë–Ω: –≤–∞–∫–∞–Ω—Å–∏–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã")
        await vacancies_create(query, user_id, session)
        logger.info("[Background] –®–∞–≥ 3 –∑–∞–≤–µ—Ä—à—ë–Ω: –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")

        logger.success(f"[Background] ‚úÖ –ò–º–ø–æ—Ä—Ç –≤–∞–∫–∞–Ω—Å–∏–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω: query='{query}'")
    except HTTPException as e:
        logger.error(f"[Background] HTTP {e.status_code}: {str(e)}")
    except Exception as e:
        logger.error(f"[Background] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –≤–∞–∫–∞–Ω—Å–∏–π: {e}", exc_info=True)
