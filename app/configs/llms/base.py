from pydantic import BaseModel, Field


class BaseLlmConfig(BaseModel):
    """
    Базовая конфигурация для LLM содержит только общие параметры.
    Конфигурации, специфичные для поставщика, должны обрабатываться отдельными классами конфигурации.

    Этот класс содержит только параметры, общие для всех поставщиков LLM.
    Для параметров, специфичных для поставщика, используйте соответствующий класс конфигурации поставщика.

    Инициализируйте экземпляр базового класса конфигурации для LLM.

    Args:
        model: Идентификатор используемой модели (например, "gpt-4o-mini", "claude-3-5-sonnet-20240620")
            По умолчанию: "None" (будет задано в настройках поставщика)
        temperature: Управляет степенью случайности выходных данных модели.
            Более высокие значения (ближе к 1) делают выходные данные более случайными, более низкие — более детерминированными.
            Диапазон: от 0,0 до 2,0. Значение по умолчанию: 0,1.
        api_key: Ключ API для поставщика LLM. Если значение None, будет предпринята попытка получить его из переменных среды.
            Значение по умолчанию None
        max_tokens: Максимальное количество токенов, генерируемых в ответе.
            Диапазон: от 1 до 4096 (зависит от модели). Значение по умолчанию: 2000.
        top_p: Параметр выборки ядра. Управляет разнообразием посредством выборки ядра.
            Более высокие значения (ближе к 1) делают выборку слов более разнообразной.
            Диапазон: от 0,0 до 1,0. Значение по умолчанию: 0,1.
        top_k: Параметр выборки top-k. Ограничивает количество токенов, рассматриваемых на каждом этапе.
            Более высокие значения делают выбор слов более разнообразным.
            Диапазон: от 1 до 40. Значение по умолчанию: 1.
        stream: Потоковая передача ответа (токен за токеном в реальном времени).
            По умолчанию: "False" (будет задано в настройках поставщика)
    """

    model: str | None = None
    temperature: float = Field(default=0.1, ge=0.0, le=2.0)
    api_key: str | None = None
    max_tokens: int = Field(default=2000, gt=0)
    top_p: float = Field(default=0.1, ge=0.0, le=1.0)
    top_k: int = Field(default=1, ge=1)
    stream: bool = False
